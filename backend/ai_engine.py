import spacy
import re
import json
from transformers import pipeline
from deepdiff import DeepDiff

# Global Model Variables (Lazy Loaded)
summarizer = None
explainer = None
nlp = None
llama_model = None
llama_processor = None
clip_classifier = None

def get_summarizer():
    global summarizer
    if summarizer is None:
        print("Loading Summarization Model...")
        try:
            summarizer = pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")
        except Exception as e:
            print(f"Error loading summarizer: {e}")
            return None
    return summarizer

def get_explainer():
    global explainer
    if explainer is None:
        print("Loading Explainer Model...")
        try:
            explainer = pipeline("text2text-generation", model="google/flan-t5-small")
        except Exception as e:
            print(f"Warning: Could not load explainer model: {e}")
            explainer = None
    return explainer

def get_nlp():
    global nlp
    if nlp is None:
        print("Loading Scispacy Medical Model...")
        try:
            # Use the installed small scientific model
            nlp = spacy.load("en_core_sci_sm")
        except OSError:
            print("Warning: en_core_sci_sm not found, falling back to en_core_web_sm. Please install the model.")
            try:
                nlp = spacy.load("en_core_web_sm")
            except:
                try:
                    from spacy.cli import download
                    download("en_core_web_sm")
                    nlp = spacy.load("en_core_web_sm")
                except Exception as e:
                    print(f"Error loading SpaCy: {e}")
    return nlp

def get_vision_models():
    """
    Lazy loads vision models. returns (llama_model, llama_processor, clip_classifier)
    """
    global llama_model, llama_processor, clip_classifier
    
    if llama_model is None and clip_classifier is None:
        print("Loading Visual AI Models...")

        # A. Try Loading Llama 3.2 Vision (11B)
        # This requires HF_TOKEN and significant RAM (>20GB) or VRAM.
        # Disabled by default for Render Free Tier / Standard deployments to prevent timeouts
        load_llama = False 
        
        if load_llama:
            try:
                model_id = "meta-llama/Llama-3.2-11B-Vision-Instruct"
                print(f"Attempting to load {model_id}...")
                
                # Use device_map="auto" to offload to standard RAM if GPU/MPS is full
                # torch_dtype=torch.bfloat16 is standard for Llama 3 on recent hardware
                llama_model = MllamaForConditionalGeneration.from_pretrained(
                    model_id,
                    torch_dtype=torch.bfloat16,
                    device_map="auto",
                )
                llama_processor = AutoProcessor.from_pretrained(model_id)
                print("SUCCESS: Llama 3.2 Vision Loaded!")
                
            except Exception as e:
                print(f"Llama 3.2 Load Failed (Falling back to CLIP): {e}")
                # Common reasons: No HF_TOKEN, OOM, or model access not granted.

        # B. Load CLIP (Zero-Shot) - Always load as fallback or primary if Llama fails
        try:
            clip_classifier = pipeline("zero-shot-image-classification", model="openai/clip-vit-base-patch32")
            if not llama_model:
                print("Using CLIP as Primary Vision Model.")
        except Exception as e:
            print(f"Warning: Could not load CLIP model: {e}")
            
    return llama_model, llama_processor, clip_classifier


def analyze_medical_image(image_bytes):
    """
    Analyzes an X-Ray/MRI image using Llama 3.2 (if avail) or CLIP.
    """
    # 1. Try Llama 3.2 Vision (Deep Analysis)
    llama_model, llama_processor, clip_classifier = get_vision_models()
    
    if llama_model and llama_processor:
        try:
            image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
            
            # Simple Medical Prompt
            prompt = "<|image|><|begin_of_text|>Analyze this medical image. Describe findings and impression."
            inputs = llama_processor(image, prompt, return_tensors="pt").to(llama_model.device)
            
            output = llama_model.generate(**inputs, max_new_tokens=150)
            description = llama_processor.decode(output[0])
            
            # Cleanup output (remove prompt parts)
            description = description.replace(prompt, "").replace("<|begin_of_text|>", "").strip()
            
            return {
                "modality": "Medical Imaging (Llama 3.2 Analysis)",
                "predictions": [{"label": "Detailed Analysis", "confidence": 100}],
                "finding": description,
                "note": "Generated by Llama 3.2 Vision (11B). Validate clinically."
            }
        except Exception as e:
            print(f"Llama Inference Failed: {e}. Falling back to CLIP.")
            # Fallthrough to CLIP

    # 2. Fallback: CLIP (Modality Detection)
    if clip_classifier:
        try:
            image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
            
            candidate_labels = [
                "chest x-ray", "brain mri", "abdominal ct scan", 
                "fetal ultrasound", "bone fracture", "medical document",
                "random noise", "random object"
            ]
            
            predictions = clip_classifier(image, candidate_labels=candidate_labels)
            
            formatted_preds = []
            is_medical_image = False
            top_label = predictions[0]['label']
            top_score = predictions[0]['score'] * 100
            
            for p in predictions[:3]:
                label = p['label']
                score = round(p['score'] * 100, 1)
                
                if any(x in label for x in ['x-ray', 'mri', 'ct scan', 'ultrasound', 'fracture', 'medical']):
                    if score > 20: is_medical_image = True
                    
                formatted_preds.append({"label": label.title(), "confidence": score})
                
            finding = f"Appearance consistent with {top_label.title()}"
            if top_label in ["random noise", "random object"] or top_score < 40:
                 finding = "Image classification uncertain. May not be a standard medical scan."
                 is_medical_image = False
                
            return {
                "modality": top_label.title() if is_medical_image else "Unknown",
                "predictions": formatted_preds,
                "finding": finding,
                "note": "AI modality detection (CLIP). For screening only."
            }
            
        except Exception as e:
            return {"error": f"CLIP Analysis Error: {str(e)}"}

    return {"error": "No Vision Models Available."}

REFERENCE_RANGES = {
    # 1. COMPLETE BLOOD COUNT (CBC + DIFFERENTIAL)
    "hemoglobin": {"min": 12.0, "max": 17.5, "unit": "g/dL"}, # Combined M/F
    "rbc count": {"min": 4.1, "max": 5.9, "unit": "million/uL"},
    "wbc count": {"min": 4000, "max": 11000, "unit": "/uL"},
    "platelets": {"min": 150000, "max": 450000, "unit": "/uL"},
    "hematocrit": {"min": 36, "max": 53, "unit": "%"},
    "mcv": {"min": 80, "max": 100, "unit": "fL"},
    "mch": {"min": 27, "max": 33, "unit": "pg"},
    "mchc": {"min": 32, "max": 36, "unit": "g/dL"},
    "rdw": {"min": 11.5, "max": 14.5, "unit": "%"},
    "neutrophils": {"min": 40, "max": 70, "unit": "%"},
    "lymphocytes": {"min": 20, "max": 40, "unit": "%"},
    "monocytes": {"min": 2, "max": 8, "unit": "%"},
    "eosinophils": {"min": 1, "max": 4, "unit": "%"},
    "basophils": {"min": 0, "max": 1, "unit": "%"},

    # 2. LIPID PROFILE (ADVANCED)
    "cholesterol": {"min": 0, "max": 200, "unit": "mg/dL"},
    "total cholesterol": {"min": 0, "max": 200, "unit": "mg/dL"},
    "ldl-c": {"min": 0, "max": 100, "unit": "mg/dL"},
    "ldl": {"min": 0, "max": 100, "unit": "mg/dL"},
    "hdl-c": {"min": 40, "max": 100, "unit": "mg/dL"}, # Using Male lower bound as generic min
    "hdl": {"min": 40, "max": 100, "unit": "mg/dL"},
    "triglycerides": {"min": 0, "max": 150, "unit": "mg/dL"},
    "vldl": {"min": 5, "max": 40, "unit": "mg/dL"},
    "non-hdl cholesterol": {"min": 0, "max": 130, "unit": "mg/dL"},
    "apob": {"min": 0, "max": 90, "unit": "mg/dL"},
    "lp(a)": {"min": 0, "max": 30, "unit": "mg/dL"},
    "cholesterol/hdl ratio": {"min": 0, "max": 4.5, "unit": "ratio"},

    # 3. LIVER FUNCTION TEST (LFT)
    "ast": {"min": 10, "max": 40, "unit": "U/L"},
    "sgot": {"min": 10, "max": 40, "unit": "U/L"},
    "alt": {"min": 7, "max": 56, "unit": "U/L"},
    "sgpt": {"min": 7, "max": 56, "unit": "U/L"},
    "alp": {"min": 44, "max": 147, "unit": "U/L"},
    "ggt": {"min": 9, "max": 48, "unit": "U/L"},
    "total bilirubin": {"min": 0.3, "max": 1.2, "unit": "mg/dL"},
    "direct bilirubin": {"min": 0.0, "max": 0.3, "unit": "mg/dL"},
    "indirect bilirubin": {"min": 0.2, "max": 0.9, "unit": "mg/dL"},
    "albumin": {"min": 3.5, "max": 5.0, "unit": "g/dL"},
    "globulin": {"min": 2.0, "max": 3.5, "unit": "g/dL"},
    "total protein": {"min": 6.0, "max": 8.3, "unit": "g/dL"},
    "a/g ratio": {"min": 1.1, "max": 2.5, "unit": "ratio"},

    # 4. KIDNEY FUNCTION TEST (KFT)
    "creatinine": {"min": 0.59, "max": 1.35, "unit": "mg/dL"}, # Combined range
    "urea": {"min": 15, "max": 40, "unit": "mg/dL"},
    "bun": {"min": 7, "max": 20, "unit": "mg/dL"},
    "uric acid": {"min": 2.4, "max": 7.0, "unit": "mg/dL"},
    "egfr": {"min": 90, "max": 200, "unit": "mL/min/1.73m²"}, # Min is critical

    # 5. DIABETES & METABOLIC
    "fasting glucose": {"min": 70, "max": 99, "unit": "mg/dL"},
    "glucose": {"min": 70, "max": 99, "unit": "mg/dL"}, # Default to fasting range standard
    "post-prandial glucose": {"min": 0, "max": 140, "unit": "mg/dL"},
    "random glucose": {"min": 0, "max": 200, "unit": "mg/dL"},
    "hba1c": {"min": 0, "max": 5.7, "unit": "%"},
    "insulin": {"min": 2, "max": 25, "unit": "uIU/mL"},
    "homa-ir": {"min": 0, "max": 2.0, "unit": "index"},

    # 6. THYROID PANEL (FULL)
    "tsh": {"min": 0.4, "max": 4.0, "unit": "mIU/L"},
    "total t3": {"min": 80, "max": 200, "unit": "ng/dL"},
    "total t4": {"min": 5.0, "max": 12.0, "unit": "ug/dL"},
    "free t3": {"min": 2.3, "max": 4.2, "unit": "pg/mL"},
    "free t4": {"min": 0.8, "max": 1.8, "unit": "ng/dL"},
    "anti-tpo": {"min": 0, "max": 35, "unit": "IU/mL"},
    "anti-tg": {"min": 0, "max": 20, "unit": "IU/mL"},

    # 7. ELECTROLYTES & MINERALS
    "sodium": {"min": 135, "max": 145, "unit": "mmol/L"},
    "potassium": {"min": 3.5, "max": 5.1, "unit": "mmol/L"},
    "chloride": {"min": 98, "max": 107, "unit": "mmol/L"},
    "calcium": {"min": 8.6, "max": 10.2, "unit": "mg/dL"},
    "ionized calcium": {"min": 1.12, "max": 1.32, "unit": "mmol/L"},
    "phosphorus": {"min": 2.5, "max": 4.5, "unit": "mg/dL"},
    "magnesium": {"min": 1.7, "max": 2.2, "unit": "mg/dL"},

    # 8. IRON STUDIES
    "serum iron": {"min": 60, "max": 170, "unit": "ug/dL"},
    "ferritin": {"min": 11, "max": 336, "unit": "ng/mL"},
    "tibc": {"min": 240, "max": 450, "unit": "ug/dL"},
    "transferrin saturation": {"min": 20, "max": 50, "unit": "%"},

    # 9. VITAMINS & NUTRITION
    "vitamin d": {"min": 30, "max": 100, "unit": "ng/mL"},
    "vitamin b12": {"min": 200, "max": 900, "unit": "pg/mL"},
    "folate": {"min": 2.7, "max": 17, "unit": "ng/mL"},
    "vitamin a": {"min": 20, "max": 60, "unit": "ug/dL"},
    "vitamin e": {"min": 5, "max": 20, "unit": "ug/mL"},
    "vitamin k": {"min": 0.2, "max": 3.2, "unit": "ng/mL"},

    # 10. INFLAMMATION & INFECTION
    "crp": {"min": 0, "max": 1.0, "unit": "mg/L"},
    "hs-crp": {"min": 0, "max": 3.0, "unit": "mg/L"},
    "esr": {"min": 0, "max": 20, "unit": "mm/hr"},
    "procalcitonin": {"min": 0, "max": 0.1, "unit": "ng/mL"},
    "il-6": {"min": 0, "max": 7, "unit": "pg/mL"},
    "d-dimer": {"min": 0, "max": 500, "unit": "ng/mL"},

    # 11. CARDIAC MARKERS
    "troponin i": {"min": 0, "max": 0.04, "unit": "ng/mL"},
    "troponin t": {"min": 0, "max": 0.01, "unit": "ng/mL"},
    "ck-mb": {"min": 0, "max": 5, "unit": "ng/mL"},
    "bnp": {"min": 0, "max": 100, "unit": "pg/mL"},
    "nt-probnp": {"min": 0, "max": 125, "unit": "pg/mL"},

    # 12. HORMONES
    "cortisol": {"min": 5, "max": 25, "unit": "ug/dL"},
    "acth": {"min": 10, "max": 60, "unit": "pg/mL"},
    "prolactin": {"min": 4, "max": 25, "unit": "ng/mL"},
    "lh": {"min": 2, "max": 15, "unit": "IU/L"},
    "fsh": {"min": 3, "max": 10, "unit": "IU/L"},
    "testosterone": {"min": 15, "max": 1000, "unit": "ng/dL"}, # Wide range M/F
    "estradiol": {"min": 30, "max": 400, "unit": "pg/mL"},

    # 13. AUTOIMMUNE
    "rf": {"min": 0, "max": 14, "unit": "IU/mL"},
    "anti-ccp": {"min": 0, "max": 20, "unit": "U/mL"},
    "dsdna": {"min": 0, "max": 30, "unit": "IU/mL"},
    "complement c3": {"min": 90, "max": 180, "unit": "mg/dL"},
    "complement c4": {"min": 10, "max": 40, "unit": "mg/dL"},

    # 14. TUMOR MARKERS
    "afp": {"min": 0, "max": 10, "unit": "ng/mL"},
    "cea": {"min": 0, "max": 3, "unit": "ng/mL"},
    "ca-125": {"min": 0, "max": 35, "unit": "U/mL"},
    "ca-19-9": {"min": 0, "max": 37, "unit": "U/mL"},
    "psa": {"min": 0, "max": 4.0, "unit": "ng/mL"},

    # 15. COAGULATION
    "pt": {"min": 11, "max": 13.5, "unit": "sec"},
    "inr": {"min": 0.8, "max": 1.2, "unit": "ratio"},
    "aptt": {"min": 25, "max": 35, "unit": "sec"},
    "fibrinogen": {"min": 200, "max": 400, "unit": "mg/dL"},

    # 16. URINE
    "ph": {"min": 4.5, "max": 8.0, "unit": "pH"},
    "specific gravity": {"min": 1.005, "max": 1.030, "unit": "sg"},

    # 18. ABG
    "ph blood": {"min": 7.35, "max": 7.45, "unit": "pH"},
    "pao2": {"min": 75, "max": 100, "unit": "mmHg"},
    "paco2": {"min": 35, "max": 45, "unit": "mmHg"},
    "hco3": {"min": 22, "max": 26, "unit": "mEq/L"},
    "o2 saturation": {"min": 95, "max": 100, "unit": "%"}
}

# Simple Medical Dictionary for Patient Translation
MEDICAL_DICTIONARY = {
    "osteopenia": "lower than normal bone density (warning sign for osteoporosis)",
    "pneumonia": "infection inflaming air sacs in one or both lungs",
    "hyperlipidemia": "high levels of fat particles (lipids) in the blood",
    "hypertension": "high blood pressure",
    "tachycardia": "faster than normal heart rate",
    "anemia": "lack of enough healthy red blood cells",
    "erythema": "redness of the skin",
    "edema": "swelling caused by excess fluid",
    "lesion": "damage or abnormal change in tissue",
    "benign": "not harmful in effect (not cancer)",
    "malignant": "very virulent or infectious (cancerous)",
    "stenosis": "narrowing of a passage in the body",
    "acute": "sudden and severe",
    "chronic": "persisting for a long time",
    "fracture": "broken bone"
}

SYNONYMS = {
    "hb": "hemoglobin",
    "hgb": "hemoglobin",
    "total cholesterol": "cholesterol",
    "t. chol": "cholesterol",
    "fbs": "glucose",
    "blood sugar": "glucose",
    "f.b.s": "glucose",
    "cre": "creatinine",
    "creat": "creatinine",
    "s. creatinine": "creatinine",
    "sgot": "ast",
    "asparts aminotransferase": "ast",
    "sgpt": "alt",
    "alanine aminotransferase": "alt",
    "trigs": "triglycerides",
    "pcv": "hematocrit",
    "hct": "hematocrit",
    "plt": "platelets",
    "platelet count": "platelets",
    "a1c": "hba1c",
    "hba1c": "hba1c",
    "glycated hemoglobin": "hba1c"
}

def normalize_name(name):
    clean = name.lower().strip().replace(":", "").replace(".", "")
    return SYNONYMS.get(clean, clean)

def extract_sections(text):
    """
    Intelligent splitting of the report into key sections.
    """
    sections = {
        "history": "",
        "findings": "",
        "impression": ""
    }
    
    # Normalize keys/headers
    text_lower = text.lower()
    
    # Heuristic indices
    idx_history = text_lower.find("history:") 
    if idx_history == -1: idx_history = text_lower.find("clinical history:")
    
    idx_findings = text_lower.find("findings:") 
    if idx_findings == -1: idx_findings = text_lower.find("technique:") # fallback
    
    idx_impression = text_lower.find("impression:")
    if idx_impression == -1: idx_impression = text_lower.find("conclusion:")
    if idx_impression == -1: idx_impression = text_lower.find("diagnosis:")

    # Sort indices to know order
    indices = sorted([
        (idx_history, "history"), 
        (idx_findings, "findings"), 
        (idx_impression, "impression")
    ], key=lambda x: x[0])
    
    # Extract
    for i, (idx, key) in enumerate(indices):
        if idx == -1: continue
        
        start = idx + len(key) + 1 # +1 for colon
        end = len(text)
        
        # Find start of next section used as end of current
        if i + 1 < len(indices):
            next_idx = indices[i+1][0]
            if next_idx != -1:
                end = next_idx
        
        content = text[start:end].strip()
        sections[key] = content

    # Fallback: if no structure found, put everything in findings
    if not any(sections.values()):
        sections["findings"] = text
        
    return sections

def simplify_text(text):
    """
    Translates medical terms to plain English using Dictionary (Fallback).
    """
    words = text.split()
    simplified = []
    
    for word in words:
        clean_word = word.lower().strip(".,()[]")
        if clean_word in MEDICAL_DICTIONARY:
            # Append term + explanation
            simplified.append(f"{word} ({MEDICAL_DICTIONARY[clean_word]})")
        else:
            simplified.append(word)
            
    return " ".join(simplified)

def explain_to_patient(text):
    """
    Uses LLM to generate a patient-friendly explanation.
    """
    if not text or not text.strip():
        return "No significant findings to explain."
        
    model = get_explainer()
    if not model:
        return simplify_text(text)
        
    try:
        # Prompt Engineering for Flan-T5
        prompt = f"Explain this medical finding to a patient in simple words: {text}"
        output = model(prompt, max_length=128, do_sample=False)
        return output[0]['generated_text']
    except Exception as e:
        print(f"Explainer Error: {e}")
        return simplify_text(text)

def detect_severity(text):
    """
    Detects severity from adjectives in the text.
    """
    text_lower = text.lower()
    if any(x in text_lower for x in ["critical", "severe", "emergency", "acute distress"]):
        return {"level": "Severe", "color": "red"}
    elif any(x in text_lower for x in ["moderate", "elevated", "abnormal"]):
        return {"level": "Moderate", "color": "orange"}
    elif any(x in text_lower for x in ["mild", "trace", "minor", "borderline"]):
         return {"level": "Mild", "color": "yellow"}
    
    return {"level": "Normal", "color": "green"}

def extract_labs_regex(text):
    """
    Improved regex to catch labs, units, and ranges.
    Prioritizes Lab Report Range > System Default.
    """
    labs = []
    
    # Pattern: Name: Value Unit [Range?]
    # Groups: 1=Name, 2=Value, 3=Unit, 4=Range(Optional)
    # Range patterns matched: (10-20), 10.0 - 20.0, > 50, < 100
    pattern = re.compile(
        r"([A-Za-z0-9\s\(\)\-\.]+?)[:\s]+(\d+(?:\.\d+)?)\s*([a-zA-Z%\^/0-9]+)\s*(?:[\(\[]?(\d+(?:\.\d+)?\s*[-–]\s*\d+(?:\.\d+)?|[<>]\s*\d+(?:\.\d+)?)[\)\]]?)?"
    )
    
    found_names = set()

    for match in pattern.finditer(text):
        raw_name = match.group(1).strip()
        value = float(match.group(2))
        unit = match.group(3).strip()
        raw_range = match.group(4)
        
        if len(raw_name) < 2 or raw_name.lower() in ["page", "date", "dob", "specimen", "patient", "collected", "reported", "result", "investigation"]:
            continue
            
        normalized = normalize_name(raw_name)
        system_ref = REFERENCE_RANGES.get(normalized)
        
        # Validation: If not in our KB, check if unit looks "lab-like"
        known_units = ["mg/dl", "g/dl", "u/l", "mmol/l", "%", "x10^3/ul", "fl", "pg", "iu/l", "ng/ml", "ug/dl", "ratio"]
        if not system_ref and unit.lower() not in known_units:
            continue

        if normalized in found_names: continue

        status = "Normal"
        ref_source = "Unknown"
        ref_str = "N/A"
        
        # 1. Try Lab Provided Range (Primary)
        lab_min = None
        lab_max = None
        
        if raw_range:
            try:
                # Handle "10 - 20"
                if "-" in raw_range or "–" in raw_range:
                    parts = re.split(r"[-–]", raw_range)
                    if len(parts) == 2:
                        lab_min = float(parts[0].strip())
                        lab_max = float(parts[1].strip())
                        ref_str = f"{lab_min} - {lab_max} {unit}"
                        ref_source = "Lab Report"
                # Handle "< 100" or "> 50"
                elif "<" in raw_range:
                     val = float(raw_range.replace("<", "").strip())
                     lab_max = val
                     lab_min = 0 # assumption for things like cholesterol
                     ref_str = f"< {val} {unit}"
                     ref_source = "Lab Report"
                elif ">" in raw_range:
                     val = float(raw_range.replace(">", "").strip())
                     lab_min = val
                     lab_max = float('inf')
                     ref_str = f"> {val} {unit}"
                     ref_source = "Lab Report"
            except:
                pass # parsing failed, fall back
        
        # 2. Fallback to System Default (Secondary)
        if ref_source == "Unknown" and system_ref:
            lab_min = system_ref['min']
            lab_max = system_ref['max']
            ref_str = f"{lab_min} - {lab_max} {system_ref['unit']}"
            ref_source = "System Default"
            
        # 3. Calculate Status
        if lab_min is not None and lab_max is not None:
            if value < lab_min:
                status = "Low"
            elif value > lab_max:
                status = "High"
        
        labs.append({
            "name": raw_name,
            "normalized_name": normalized,
            "value": value,
            "unit": unit,
            "status": status,
            "reference": ref_str,
            "source": ref_source
        })
        found_names.add(normalized)
        
    return labs

def calculate_risk(labs):
    risks = []
    lab_map = {l['normalized_name']: l for l in labs}
    
    # CV Risk
    chol = lab_map.get('cholesterol')
    ldl = lab_map.get('ldl')
    if chol and chol['value'] > 240:
        risks.append({"type": "Cardiovascular", "status": "High Risk", "detail": "Total Cholesterol > 240"})
    elif chol and chol['value'] > 200:
        risks.append({"type": "Cardiovascular", "status": "Moderate Risk", "detail": "Total Cholesterol > 200"})
    elif ldl and ldl['value'] > 160:
        risks.append({"type": "Cardiovascular", "status": "High Risk", "detail": "LDL > 160"})

    # Diabetes
    gluc = lab_map.get('glucose')
    if gluc and gluc['value'] > 126:
        risks.append({"type": "Diabetes", "status": "High Risk", "detail": "Fasting Glucose > 126"})
        
    # Kidney
    creat = lab_map.get('creatinine')
    if creat and creat['value'] > 1.4:
         risks.append({"type": "Kidney Health", "status": "Elevated Risk", "detail": "Creatinine High"})

    return risks

def generate_recommendations(labs, risks):
    recs = []
    lab_map = {l['normalized_name']: l for l in labs}

    if any(r['type'] == 'Cardiovascular' for r in risks):
        recs.append({"action": "Diet", "advice": "Reduce saturated fats and cholesterol intake. Consider Mediterranean diet."})
        recs.append({"action": "Exercise", "advice": "Aim for 150 minutes of moderate aerobic activity per week."})
    
    if any(r['type'] == 'Diabetes' for r in risks):
         recs.append({"action": "Diet", "advice": "Monitor carbohydrate intake. Avoid sugary beverages."})
         recs.append({"action": "Monitoring", "advice": "Check HbA1c to assess long-term glucose control."})

    if not recs:
        recs.append({"action": "General", "advice": "Maintain current healthy lifestyle."})
        recs.append({"action": "Screening", "advice": "Routine annual physical."})
    else:
        recs.append({"action": "Follow-up", "advice": "Repeat lipids/metabolic panel in 3-6 months."})

    return recs

def chunk_text(text, chunk_size=3000, overlap=200):
    """
    Splits text into chunks with overlap for processing long documents.
    """
    chunks = []
    start = 0
    text_len = len(text)
    
    while start < text_len:
        end = start + chunk_size
        chunks.append(text[start:end])
        start += (chunk_size - overlap)
        
    return chunks

def summarize_text(text):
    """
    Recursively summarizes long text (Map-Reduce style).
    """
    model = get_summarizer()
    if not model: return "Summary unavailable."
    
    # 1. If short enough, summarize directly
    if len(text) < 3000:
        try:
            # max_length usually 1024 for BART, but we limit output here
            # Input truncation is handled by the model pipeline usually, but we want to be safe
            summary = model(text[:3000], max_length=150, min_length=40, do_sample=False, truncation=True)
            return summary[0]['summary_text']
        except Exception as e:
            print(f"Summary Error (Short): {e}")
            return "Summary generation failed."

    # 2. Long Document Strategy
    print(f"Long text detected ({len(text)} chars). Chunking...")
    chunks = chunk_text(text)
    chunk_summaries = []
    
    for i, chunk in enumerate(chunks):
        try:
            res = model(chunk, max_length=100, min_length=30, do_sample=False, truncation=True)
            chunk_summaries.append(res[0]['summary_text'])
        except Exception as e:
            print(f"Error summarizing chunk {i}: {e}")
            
    # 3. Final Summary of Summaries
    combined_summary_text = " ".join(chunk_summaries)
    try:
         final_summary = model(combined_summary_text[:3000], max_length=200, min_length=50, do_sample=False, truncation=True)
         return final_summary[0]['summary_text']
    except Exception as e:
        print(f"Summary Error (Final): {e}")
        return combined_summary_text[:500] + "..."

def get_follow_up_tests(labs, risks):
    tests = []
    lab_map = {l['normalized_name']: l for l in labs}
    
    # 1. Lipid / Cardiovascular
    if any(r['type'] == 'Cardiovascular' for r in risks):
        tests.append({
            "test": "Lipid Fractionation",
            "reason": "Detailed breakdown of cholesterol particles to assess risk more accurately."
        })
        tests.append({
            "test": "Lipoprotein(a)",
            "reason": "Genetic marker for cardiovascular risk."
        })
        tests.append({
            "test": "ApoB",
            "reason": "Direct measure of atherogenic particles."
        })

    # 2. Diabetes / Metabolic
    glucose = lab_map.get('glucose')
    hba1c = lab_map.get('hba1c')
    if (glucose and glucose['status'] == 'High') or (hba1c and hba1c['status'] == 'High'):
        tests.append({
            "test": "C-Peptide & Insulin",
            "reason": "Distinguish between Type 1 and Type 2 diabetes / assess insulin resistance."
        })
        tests.append({
            "test": "Urine Microalbumin",
            "reason": "Screen for early kidney damage due to sugar levels."
        })

    # 3. Anemia
    hemoglobin = lab_map.get('hemoglobin')
    if hemoglobin and hemoglobin['status'] == 'Low':
        tests.append({
            "test": "Iron Studies (Ferritin, TIBC)",
            "reason": "Determine if anemia is due to iron deficiency."
        })
        tests.append({
            "test": "Vitamin B12 & Folate",
            "reason": "Rule out nutritional deficiency."
        })
        tests.append({
            "test": "Reticulocyte Count",
            "reason": "Check bone marrow response to anemia."
        })

    # 4. Thyroid
    tsh = lab_map.get('tsh')
    if tsh and tsh['status'] != 'Normal':
        tests.append({
            "test": "Free T3 & Free T4",
            "reason": "Confirm extent of thyroid dysfunction."
        })
        tests.append({
            "test": "Thyroid Antibodies (TPO)",
            "reason": "Check for autoimmune causes like Hashimoto's."
        })

    # 5. Inflammation / Infection
    wbc = lab_map.get('wbc')
    if wbc and wbc['status'] == 'High':
        tests.append({
            "test": "WBC Differential",
            "reason": "Identify if infection is bacterial, viral, or other."
        })
        tests.append({
            "test": "CRP & ESR",
            "reason": "General markers of inflammation in the body."
        })

    # 6. Liver
    alt = lab_map.get('alt')
    ast = lab_map.get('ast')
    if (alt and alt['status'] == 'High') or (ast and ast['status'] == 'High'):
        tests.append({
            "test": "Hepatitis Panel",
            "reason": "Rule out viral hepatitis."
        })
        tests.append({
            "test": "Abdominal Ultrasound",
            "reason": "Check for fatty liver or structural issues."
        })
        
    return tests

def compare_labs(current_labs, previous_labs):
    """
    Matches labs by normalized name and calculates trends.
    """
    prev_map = {l['normalized_name']: l for l in previous_labs}
    
    for lab in current_labs:
        norm = lab['normalized_name']
        if norm in prev_map:
            prev = prev_map[norm]
            lab['previous_value'] = prev['value']
            
            diff = lab['value'] - prev['value']
            lab['change'] = round(diff, 2)
            
            # Trend Logic
            # For most things, lower is better if it was High, higher is better if Low.
            # Simplified Logic:
            if abs(diff) < 0.1:
                lab['trend'] = 'Stable'
            elif diff > 0:
                lab['trend'] = 'Increasing'
            else:
                lab['trend'] = 'Decreasing'
                
            # Heuristic for "Better/Worse" (Very basic)
            if lab['status'] == 'High' and diff < 0:
                lab['trend_context'] = 'Improving'
            elif lab['status'] == 'Low' and diff > 0:
                lab['trend_context'] = 'Improving'
            elif lab['status'] == 'Normal':
                lab['trend_context'] = 'Stable'
            else:
                lab['trend_context'] = 'Worsening'
                
    return current_labs

def analyze_full_report(current_text, previous_text=None):
    # 1. Structural Parsing
    sections = extract_sections(current_text)
    
    # 2. Lab Extraction
    labs = extract_labs_regex(current_text)
    
    # 3. Risk & Recs
    risks = calculate_risk(labs)
    recommendations = generate_recommendations(labs, risks)
    follow_up_tests = get_follow_up_tests(labs, risks)
    
    # 4. Intelligence Layers
    # Patient-Friendly Translation of Findings/Impression
    patient_findings = explain_to_patient(sections['findings'])
    patient_impression = explain_to_patient(sections['impression'])
    
    # Severity Detection per section
    severity = {
        "findings": detect_severity(sections['findings']),
        "impression": detect_severity(sections['impression'])
    }
    
    # 5. Summary (Technical)
    summary = summarize_text(current_text)
    
    # Entities
    nlp_model = get_nlp()
    if nlp_model:
        doc = nlp_model(current_text)
        entities = [{"text": e.text, "label": "ENTITY"} for e in doc.ents]
    else:
        entities = []
    entities = [dict(t) for t in {tuple(d.items()) for d in entities}]

def detect_report_type(text):
    """
    Determines if the report is 'Lab' or 'Radiology' based on keywords.
    """
    text_lower = text.lower()
    
    # Radiology Signals
    rad_keywords = [
        "mri", "ct scan", "computed tomography", "x-ray", "ultrasound", 
        "sonography", "technique:", "exam:", "examination:", "contrast", 
        "sagittal", "coronal", "axial", "t1", "t2", "echo", "doppler"
    ]
    
    # Lab Signals
    lab_keywords = [
        "hemoglobin", "glucose", "cholesterol", "creatinine", 
        "reference range", "units", "u/l", "mg/dl", "g/dl"
    ]
    
    rad_score = sum(1 for k in rad_keywords if k in text_lower)
    lab_score = sum(1 for k in lab_keywords if k in text_lower)
    
    if rad_score > lab_score:
        return "Radiology"
    return "Lab"

def analyze_radiology(text, sections):
    """
    Specialized analysis for imaging reports.
    """
    findings = sections.get('findings', '')
    impression = sections.get('impression', '')
    
    # NLP Extraction for Abnormalities
    nlp_model = get_nlp()
    if nlp_model:
        doc = nlp_model(findings + " " + impression)
        
        # Heuristic: Find sentences with 'alert' words
        abnormalities = []
        alert_terms = [
            "mass", "nodule", "fracture", "herniation", "stenosis", 
            "lesion", "cyst", "tumor", "infarct", "hemorrhage", 
            "effusion", "opacification", "tear", "rupture", "dislocation"
        ]
        
        for sent in doc.sents:
            sent_text = sent.text.strip()
            if any(term in sent_text.lower() for term in alert_terms):
                # Check if it is negated? (Basic check)
                if "no " not in sent_text.lower() and "unremarkable" not in sent_text.lower():
                    abnormalities.append(sent_text)
    else:
        abnormalities = []
                
    # Deduplicate
    abnormalities = list(set(abnormalities))
    
    return {
        "modality": "Unknown Imaging", # Could extract "MRI of Brain" here later
        "abnormalities": abnormalities,
        "is_normal": len(abnormalities) == 0
    }


def get_recommended_specialists(risks, report_type="Lab"):
    """
    Maps risks/abnormalities to medical specialists.
    """
    specialists = set()
    
    # 1. Logic based on Risks (Lab/General)
    for risk in risks:
        r_type = risk.get('type', '').lower()
        detail = risk.get('detail', '').lower()
        
        if "cardiovascular" in r_type or "cholesterol" in detail:
            specialists.add("Cardiologist")
        elif "diabetes" in r_type or "glucose" in detail or "thyroid" in detail:
            specialists.add("Endocrinologist")
        elif "kidney" in r_type or "creatinine" in detail:
            specialists.add("Nephrologist")
        elif "anemia" in r_type or "hemoglobin" in detail:
            specialists.add("Hematologist")
        elif "liver" in r_type or "hepatitis" in detail:
            specialists.add("Hepatologist")
            
    # 2. Logic based on Radiology Findings
    if report_type == "Radiology":
        # Broad mapping based on likely body parts (basic heuristic)
        # In a real app, we'd check if "Brain MRI" -> Neurologist
        pass 
        
    # Default fallbacks
    if not specialists:
        if report_type == "Radiology":
             specialists.add("Orthopedist") # skeletal stuff
             specialists.add("Radiologist") # for consult
        else:
             specialists.add("Primary Care Physician")
             
    return list(specialists)

def analyze_full_report(current_text, previous_text=None):
    # 1. Structural Parsing (Common for both)
    sections = extract_sections(current_text)
    
    # 2. Detect Type
    report_type = detect_report_type(current_text)
    
    # 3. Summary (Common)
    summary = summarize_text(current_text)
    
    # 4. Entities (Common)
    nlp_model = get_nlp()
    if nlp_model:
        doc = nlp_model(current_text)
        entities = [{"text": e.text, "label": "ENTITY"} for e in doc.ents]
    else:
        entities = []
    entities = [dict(t) for t in {tuple(d.items()) for d in entities}]
    
    result = {
        "report_type": report_type,
        "summary": summary,
        "sections": sections,
        "entities": entities
    }

    if report_type == "Radiology":
        rad_analysis = analyze_radiology(current_text, sections)
        
        # Patient Explanation for Radiology
        patient_impression = explain_to_patient(sections['impression'])
        
        # Calculate Specialists for Radiology (Basic)
        # If fracture -> Orthopedist
        specialists = ["Primary Care Physician"]
        for ab in rad_analysis.get('abnormalities', []):
            if "fracture" in ab.lower() or "bone" in ab.lower():
                 specialists.append("Orthopedist")
            if "tumor" in ab.lower() or "mass" in ab.lower():
                 specialists.append("Oncologist")
        specialists = list(set(specialists))

        result.update({
            "radiology": rad_analysis,
            "patient_view": {
                "findings": "See imaging details below.",
                "impression": patient_impression,
                "explanation": "Imaging reports describe visual findings. We've highlighted key abnormalities."
            },
            "risks": [], 
            "labs": [], 
            "recommendations": [],
            "follow_up_tests": [],
            "specialists": specialists 
        })
        
        if rad_analysis['abnormalities']:
            result['risks'].append({"type": "Imaging Finding", "status": "Observation", "detail": "Abnormalities detected in scan."})
            
    else:
        # Standard Lab Analysis
        labs = extract_labs_regex(current_text)
        risks = calculate_risk(labs)
        recommendations = generate_recommendations(labs, risks)
        follow_up_tests = get_follow_up_tests(labs, risks)
        
        # V16: Specialist Mapping
        specialists = get_recommended_specialists(risks, "Lab")
        
        patient_findings = explain_to_patient(sections['findings'])
        patient_impression = explain_to_patient(sections['impression'])
        
        severity = {
            "findings": detect_severity(sections['findings']),
            "impression": detect_severity(sections['impression'])
        }
        
        comparison = {}
        if previous_text:
            prev_labs = extract_labs_regex(previous_text)
            labs = compare_labs(labs, prev_labs)
            comparison = {
                "previous_labs": prev_labs,
                "diff_summary": f"Compared against previous report." 
            }
            
        result.update({
            "patient_view": {
                "findings": patient_findings,
                "impression": patient_impression,
                "explanation": "Simplified medical terms are shown in parentheses."
            },
            "severity": severity,
            "labs": labs,
            "risks": risks,
            "recommendations": recommendations,
            "follow_up_tests": follow_up_tests,
            "comparison": comparison,
            "specialists": specialists
        })

    return result
